import { NextResponse } from 'next/server';

// é…ç½®Google AI API
const PROJECT_ID = process.env.GOOGLE_PROJECT_ID || process.env.GOOGLE_CLOUD_PROJECT;
const LOCATION = process.env.GOOGLE_CLOUD_LOCATION || 'us-central1';
const MODEL_ID = process.env.GOOGLE_AI_MODEL || 'gemini-2.5-flash';

interface ChatMessage {
  role: 'user' | 'model' | 'system';
  content: string;
}

interface ChatRequest {
  messages: ChatMessage[];
}

export async function POST(req: Request) {
  try {
    const body: ChatRequest = await req.json();
    const { messages } = body;

    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'Invalid messages format' },
        { status: 400 }
      );
    }

    // ä½¿ç”¨Vertex AI API
    try {
      const vertexAI = await import('@google-cloud/vertexai');
      const { VertexAI } = vertexAI;

      const vertexAIInstance = new VertexAI({
        project: PROJECT_ID,
        location: LOCATION,
      });

      const generativeModel = vertexAIInstance.getGenerativeModel({
        model: MODEL_ID,
      });

      // è½¬æ¢æ¶ˆæ¯æ ¼å¼
      const history = messages.slice(0, -1).map(msg => ({
        role: msg.role === 'system' ? 'user' : msg.role,
        parts: [{ text: msg.content }],
      }));

      const lastMessage = messages[messages.length - 1];

      const result = await generativeModel.generateContent({
        contents: [
          ...history,
          {
            role: lastMessage.role === 'system' ? 'user' : lastMessage.role,
            parts: [{ text: lastMessage.content }],
          },
        ],
        generationConfig: {
          maxOutputTokens: 2048,
          temperature: 0.7,
        },
      });

      const response = result.response;
      const text = response.candidates?.[0]?.content?.parts?.[0]?.text || '';

      return NextResponse.json({ response: text });
    } catch (vertexError) {
      console.error('Vertex AI failed, trying alternative method:', vertexError);
      return await callVertexAIWithAPIKey(messages);
    }
  } catch (error) {
    console.error('AI Chat API Error:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}

// å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨APIå¯†é’¥è°ƒç”¨Vertex AI
async function callVertexAIWithAPIKey(messages: ChatMessage[]) {
  try {
    const API_KEY = process.env.GOOGLE_AI_API_KEY;

    if (!API_KEY) {
      throw new Error('API Key not configured');
    }

    // ä½¿ç”¨REST APIè°ƒç”¨
    const endpoint = `https://generativelanguage.googleapis.com/v1beta/models/${MODEL_ID}:generateContent?key=${API_KEY}`;

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼
    const contents = messages.map(msg => ({
      role: msg.role === 'system' ? 'user' : msg.role,
      parts: [{ text: msg.content }],
    }));

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents,
        generationConfig: {
          maxOutputTokens: 2048,
          temperature: 0.7,
        },
      }),
    });

    if (!response.ok) {
      const errorData = await response.text();
      console.error('Google AI API Error Response:', errorData);
      throw new Error(`Google AI API error: ${response.status}`);
    }

    const data = await response.json();
    const text = data.candidates?.[0]?.content?.parts?.[0]?.text || '';

    return NextResponse.json({ response: text });
  } catch (error) {
    console.error('API Key method failed:', error);

    // æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šæ¨¡æ‹ŸAIå“åº”
    if (messages.length > 0) {
      const lastMessage = messages[messages.length - 1].content.toLowerCase();

      // ç®€å•çš„è§„åˆ™å“åº”
      if (lastMessage.includes('åˆ›å»º') || lastMessage.includes('æ–°å»º')) {
        const mockResponse = `æˆ‘ç†è§£æ‚¨æƒ³è¦åˆ›å»ºä»»åŠ¡ã€‚è¯·å‘Šè¯‰æˆ‘ï¼š
1. ä»»åŠ¡å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ
2. å¸Œæœ›æ·»åŠ åˆ°å“ªä¸€åˆ—ï¼Ÿ
3. æ˜¯å¦éœ€è¦è®¾ç½®ä¼˜å…ˆçº§ï¼Ÿ`;
        return NextResponse.json({ response: mockResponse });
      }

      if (lastMessage.includes('çŠ¶æ€') || lastMessage.includes('æŸ¥çœ‹')) {
        const mockResponse = `å½“å‰çœ‹æ¿çŠ¶æ€å·²åŠ è½½å®Œæˆã€‚æˆ‘å¯ä»¥å¸®æ‚¨ï¼š
- åˆ›å»ºæ–°ä»»åŠ¡
- ç§»åŠ¨ä»»åŠ¡åˆ°ä¸åŒåˆ—
- æ›´æ–°ä»»åŠ¡ä¿¡æ¯
- æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…

è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦åšä»€ä¹ˆï¼Ÿ`;
        return NextResponse.json({ response: mockResponse });
      }

      if (lastMessage.includes('å¸®åŠ©') || lastMessage.includes('æ€ä¹ˆç”¨')) {
        const mockResponse = `æˆ‘æ˜¯æ‚¨çš„AIçœ‹æ¿åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ï¼š

ğŸ“‹ ä»»åŠ¡ç®¡ç†ï¼š
â€¢ åˆ›å»ºæ–°ä»»åŠ¡ï¼š"åˆ›å»ºä¸€ä¸ªä»»åŠ¡ï¼šè®¾è®¡ç™»å½•é¡µé¢"
â€¢ ç§»åŠ¨ä»»åŠ¡ï¼š"æŠŠä»»åŠ¡Aç§»åŠ¨åˆ°è¿›è¡Œä¸­"
â€¢ æ›´æ–°ä»»åŠ¡ï¼š"æ›´æ–°ä»»åŠ¡Açš„ä¼˜å…ˆçº§ä¸ºé«˜"

ğŸ“Š çœ‹æ¿ç®¡ç†ï¼š
â€¢ æŸ¥çœ‹çŠ¶æ€ï¼š"æ˜¾ç¤ºå½“å‰çœ‹æ¿çŠ¶æ€"
â€¢ åˆ›å»ºåˆ—ï¼š"æ–°å»ºä¸€ä¸ªåˆ—åä¸ºæµ‹è¯•ä¸­"

ğŸ’¡ æ™ºèƒ½åˆ†æï¼š
â€¢ ä»»åŠ¡æ€»ç»“ï¼š"æ€»ç»“ä¸€ä¸‹å½“å‰çš„ä»»åŠ¡æƒ…å†µ"
â€¢ ä¼˜å…ˆçº§å»ºè®®ï¼š"å¸®æˆ‘è¯„ä¼°ä»»åŠ¡ä¼˜å…ˆçº§"

è¯·é—®éœ€è¦æˆ‘å¸®æ‚¨åšä»€ä¹ˆï¼Ÿ`;
        return NextResponse.json({ response: mockResponse });
      }
    }

    const mockResponse = `æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ã€‚ç”±äºAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚æ‚¨å¯ä»¥ï¼š
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. è”ç³»ç®¡ç†å‘˜ç¡®è®¤AIæœåŠ¡çŠ¶æ€
3. ç¨åé‡è¯•

å¦‚æœæ‚¨éœ€è¦ç«‹å³å¤„ç†ä»»åŠ¡ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨çœ‹æ¿ç•Œé¢è¿›è¡Œæ“ä½œã€‚`;

    return NextResponse.json({ response: mockResponse });
  }
}

// æ£€æŸ¥APIå¯ç”¨æ€§
export async function GET() {
  return NextResponse.json({
    status: 'AI Chat API is running',
    projectId: PROJECT_ID ? 'configured' : 'not configured',
    location: LOCATION,
    model: MODEL_ID
  });
}